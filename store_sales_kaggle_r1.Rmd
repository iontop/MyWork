---
title: "store_sales"
author: "J.H AHN"
date: '2021 12 14 '
output: html_document
---

```{r setup, include=FALSE}
rm(list = ls())
gc()

library(tidymodels)
library(tidyverse)
library(tsibble)
library(feasts)
library(fable)
library(fabletools)
library(lubridate)
library(timetk)

knitr::opts_chunk$set(echo = TRUE)
options(tidymodels.dark = TRUE)

```

## Import data

```{r Import}
raw_test <- read_csv("D:/R_DATA/store-sales-time-series-forecasting/test.csv")
raw_train <- read_csv("D:/R_DATA/store-sales-time-series-forecasting/train.csv")
raw_oil <- read_csv("D:/R_DATA/store-sales-time-series-forecasting/oil.csv")
raw_holiday <- read_csv("D:/R_DATA/store-sales-time-series-forecasting/holidays_events.csv")
raw_store <- read_csv("D:/R_DATA/store-sales-time-series-forecasting/stores.csv")
raw_transactions <- read_csv("D:/R_DATA/store-sales-time-series-forecasting/transactions.csv")

```


## binding raw files

```{r bind_train_test_csv}
raw_test$set <- "test"
raw_train$set <- "train"

raw_full <- 
  bind_rows(raw_test, raw_train)

# c(nrow(raw_train), nrow(raw_test), nrow(raw_full))

```


## recode family


```{r}
raw_full$family <- 
  raw_full$family %>% recode(
    `AUTOMOTIVE` = 1, `BABY CARE` = 2, `BEAUTY` = 3,
    `BEVERAGES` = 4, `BOOKS` = 5, `BREAD/BAKERY` = 6,
    `CELEBRATION` = 7, `CLEANING` = 8, `DAIRY` = 9,
    `DELI` = 10, `EGGS` = 11, `FROZEN FOODS` = 12,
    `GROCERY I` = 13, `GROCERY II` = 14, `HARDWARE` = 15,
    `HOME AND KITCHEN I` = 16, `HOME AND KITCHEN II` = 17, `HOME APPLIANCES` = 18,
    `HOME CARE` = 19, `LADIESWEAR` = 20, `LAWN AND GARDEN` = 21,
    `LINGERIE` = 22, `LIQUOR,WINE,BEER` = 23, `MAGAZINES` = 24,
    `MEATS` = 25, `PERSONAL CARE` = 26, `PET SUPPLIES` = 27,
    `PLAYERS AND ELECTRONICS` = 28, `POULTRY` = 29, `PREPARED FOODS` = 30,
    `PRODUCE` = 31, `SCHOOL AND OFFICE SUPPLIES` = 32, `SEAFOOD` = 33
  )


```


## Merge data


```{r merge_earth_quake}
raw_full$earthquake <-
  if_else(raw_full$date >= as.Date("2014-08-12") &
            raw_full$date <= as.Date("2014-08-16"), 1, 0)

```




```{r merge_holiday}
simple_holiday <- 
  raw_holiday %>% 
  select(date, type, transferred)

nrow(simple_holiday) # for checking, delete later

# removed duplicated rows
simple_holiday <- 
  simple_holiday %>% distinct(date, .keep_all = TRUE)

nrow(simple_holiday) # for checking, delete later

simple_holiday <- simple_holiday %>% 
  filter_by_time(.date_var = date,
                 .start_date = min(raw_full$date), 
                 .end_date = max(raw_full$date)) %>% 
  mutate(working = case_when(type == "Holiday"&transferred == "FALSE" ~ 0,
                             type %in% c("Transfer", "Additional","Event") ~ 0,
                             TRUE ~ 1)
  )


raw_full <-
  raw_full %>%
  left_join(simple_holiday, by = 'date')


raw_full$working <- if_else(is.na(raw_full$working), 0, raw_full$working)


raw_full <- raw_full %>% select(-c(type, transferred))

```



## Merge oil_price


```{r}
oil_tsbl <- as_tsibble(raw_oil, index = date, regular = TRUE)

fit_oilprice <- 
  oil_tsbl %>% 
  fill_gaps(.full = TRUE) %>%
  model(randomwalk = RW(dcoilwtico ~ drift()))


fitted_oil <- 
  fit_oilprice %>% 
  augment() %>% 
  filter(.model == "randomwalk") %>% 
  select(c(date, dcoilwtico, .fitted))


fitted_oil <- 
  fitted_oil %>% 
  mutate(dcoilwtico = case_when(is.na(dcoilwtico) ~ .fitted,
                                TRUE ~ fitted_oil$dcoilwtico))

fitted_oil$dcoilwtico[1] <- fitted_oil$dcoilwtico[2]

fitted_oil <- 
  fitted_oil %>% 
  rename(oil_price = dcoilwtico) %>% 
  select(-.fitted)

raw_full <- 
  raw_full %>% 
  left_join(fitted_oil, by = 'date')



```

```{r}
eval_oil_tsbl <- oil_tsbl %>% filter(date >= as.Date("2017-08-01"))
eval_fitted_oil <- fitted_oil %>% filter(date >= as.Date("2017-08-01"))

ggplot() +
  geom_point(data = eval_oil_tsbl, aes(date, dcoilwtico), color = "#ff8c00", size = 2) +
  geom_point(data = eval_fitted_oil, aes(date, oil_price), color = "#8B0000", size = 1) +
  geom_line(data = eval_fitted_oil, aes(date, oil_price), color = "#8B0000") +
  scale_x_date(breaks = date_breaks("day"), labels = date_format("%m\n%d"))

```




## merge transaction


```{r merge_transaction}

raw_trs <- 
  raw_transactions %>% 
  left_join(raw_store, by = 'store_nbr')

tsbl_trs <- 
  raw_trs %>% 
  select(date, transactions, store_nbr, state, city) %>% 
  as_tsibble(index = date, key = c(store_nbr, state, city))


tsbl_trs <- 
  tsbl_trs %>% fill_gaps()

tsbl_trs$transactions <- 
  if_else(is.na(tsbl_trs$transactions), 0, tsbl_trs$transactions)


fit_trs <- 
  tsbl_trs %>% 
  model(base = SNAIVE(transactions ~ lag("1 year")))

# estimate daily transaction using SNAIVE
fcast_trs <- 
  fit_trs %>% 
  forecast(h = "15 days")

fitted_trs <- 
  as.data.frame(fcast_trs) %>% 
  select(-c(.model, transactions)) %>% 
  rename(transactions = .mean)

raw_full <- 
  raw_full %>% 
  left_join(raw_store %>% select('store_nbr', 'city', 'state'),
            by = 'store_nbr')

hist_trs <- 
  raw_trs %>% tibble() %>% 
  select(-c(type, cluster))

full_trs <- 
  bind_rows(hist_trs, fitted_trs)

raw_full <- 
  raw_full %>% 
  left_join(full_trs, by = c('date', 'store_nbr', 'city', 'state')) %>% 
  select(-ends_with('.x'))

raw_full$transactions <-
  if_else(is.na(raw_full$transactions), 0, raw_full$transactions)

```


```{r}
eval_hist_trs <- hist_trs %>% filter(date >= as.Date("2017-03-01"), store_nbr == 24)
eval_fitted_trs <- fitted_trs %>% filter(store_nbr == 24)

ggplot()+
  geom_line(data = eval_hist_trs, aes(date, transactions), color = "#191970") +
  geom_line(data = eval_fitted_trs, aes(date, transactions), color = "#8B0000") +
  scale_x_date(labels = date_format("%B"), breaks = date_breaks("1 month"))


```




```{r}
full_trs %>% filter(date > as.Date("2017-05-01"), store_nbr > 0, store_nbr < 7) %>% 
  ggplot(aes(date, transactions, color = as.factor(store_nbr))) + geom_line() +
  facet_wrap(~ store_nbr, scales = "free_y", ncol = 2)


```


```{r}
full_trs %>% filter(date > as.Date("2017-05-01"), store_nbr > 8, store_nbr < 15) %>% 
  ggplot(aes(date, transactions, color = as.factor(store_nbr))) + geom_line() +
  facet_wrap(~ store_nbr, scales = "free_y", ncol = 2)+
  scale_x_date(breaks = date_breaks("1 month"), labels = date_format("%B"))


```


### change column properties

```{r change_column_properties}
raw_full <- 
  raw_full %>% select(-c(city, state))

raw_full$store_nbr <- as.numeric(raw_full$store_nbr)
# raw_full$family <- as.numeric(raw_full$family)
raw_full$earthquake <- as.numeric(raw_full$earthquake)
raw_full$working <- as.numeric(raw_full$working)

```



### decompose date


```{r decompose_date}
raw_full$year <- year(raw_full$date)
raw_full$month <- month(raw_full$date)
raw_full$day <- day(raw_full$date)
raw_full$wday <- wday(raw_full$date)
raw_full$week <- week(raw_full$date)

```



### generate lag column

```{r generate_lag_column}
# raw_full <- 
#   raw_full %>% group_by(store_nbr, family) %>% 
#   mutate(lag1 = dplyr::lag(sales, n=1, default = NA)) %>% 
#   ungroup()
# 
# raw_full <- 
#   raw_full %>% group_by(store_nbr, family) %>% 
#   mutate(lag7 = dplyr::lag(sales, n=7, default = NA)) %>% 
#   ungroup()
# 
# raw_full <- 
#   raw_full %>% group_by(store_nbr, family) %>% 
#   mutate(lag14 = dplyr::lag(sales, n=14, default = NA)) %>% 
#   ungroup()

```



### generate ratio column


```{r generate_ratio_column}
raw_full <- 
  raw_full %>% group_by(date, store_nbr) %>%
  mutate(daily_sales = sum(sales)) %>% 
  ungroup() %>% 
  mutate(ratio_sales = case_when(daily_sales > 0  ~ round(sales / daily_sales, 5),
                                 TRUE ~ 0))

raw_full$daily_transactions <- raw_full$transactions

raw_full <- 
  raw_full %>% 
  mutate(transactions = case_when(daily_transactions > 0 ~ round(daily_transactions * ratio_sales,3),
                                  TRUE ~ 0))

```


### split the data set by store_nbr and family


```{r group_split_data}

df <- raw_full %>%
  group_by(store_nbr, family)

df_set <- df %>% group_split()

```



```{r}
# split data
df_train <- df_set[[31]] %>% filter(set == "train")
df_test <- df_set[[31]] %>% filter(set == "test")

df_split <- initial_time_split(df_train)
df_analysis <- training(df_split)
df_assess <- testing(df_split)

```


```{r}
ggplot() +
  geom_line(data = df_analysis, aes(date, sales), color = "#191970") +
  geom_line(data = df_assess, aes(date, sales), color = "#8B0000")

```

```{r}
df_slice <- 
  df_analysis %>% 
  rolling_origin(initial = 728, assess = 30, cumulative = TRUE,
                 skip = 30, lag = 0)

```


```{r}
slice_check <- list()

chk_date <- function(n){
slice_check <- c(
                 df_slice$splits[[n]] %>% analysis() %>% select(date) %>% head(1) %>% pull(),
                 df_slice$splits[[n]] %>% analysis() %>% select(date) %>% tail(1) %>% pull(),
                 df_slice$splits[[n]] %>% assessment() %>% select(date) %>% head(1) %>% pull(),
                 df_slice$splits[[n]] %>% assessment() %>% select(date) %>% tail(1) %>% pull()
)
}

 for(i in 1:nrow(df_slice)) {
   slice_check[[i]] <- chk_date(i)
 }
 
 
chk_res <- t(as.data.frame(slice_check, row.names = NULL)) %>% tibble()

chk_res

```

```{r}
# set model specification (no need preprocessing)
cart_spec <- 
   decision_tree(cost_complexity = tune(), min_n = tune()) %>% 
   set_engine("rpart") %>% 
   set_mode("regression")

library(baguette)
bag_cart_spec <- 
   bag_tree() %>% 
   set_engine("rpart", times = 50L) %>% 
   set_mode("regression")

rf_spec <- 
   rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
   set_engine("ranger") %>% 
   set_mode("regression")

xgb_spec <- 
   boost_tree(tree_depth = tune(), learn_rate = tune(), loss_reduction = tune(), 
              min_n = tune(), sample_size = tune(), trees = tune()) %>% 
   set_engine("xgboost") %>% 
   set_mode("regression")

library(rules)
cubist_spec <- 
   cubist_rules(committees = tune(), neighbors = tune()) %>% 
   set_engine("Cubist") 
  

```


```{r}
# recipe
base_rec <- 
  recipe(sales ~ ., data = df_analysis) %>% 
  update_role(c(id, date, store_nbr, family, set, transactions, daily_sales, ratio_sales), 
              new_role = "id") %>% 
  step_impute_knn(all_predictors()) %>%
  step_zv(all_numeric_predictors())

# set workflow
base_wf <- 
  workflow() %>% 
  add_model(xgb_spec) %>% 
  add_recipe(base_rec) 

```


```{r}
library(tictoc)
doParallel::registerDoParallel()

tic()
set.seed(234)
base_res <- 
  base_wf %>% 
  tune_grid(
    resamples = df_slice,
    grid = 5,
    metrics = metric_set(rmse),
    control = control_grid(verbose = TRUE, save_pred = FALSE, save_workflow = FALSE)
  )
toc()

```

```{r}
# finalize workflow using best result
final_wf <- 
  base_wf %>% 
  finalize_workflow(select_best(base_res, metric = "rmse"))


```


```{r}
# trained fit
base_fit <-
  final_wf %>% 
  last_fit(df_split)

ext_wf <- 
  extract_workflow(base_fit)

```

```{r}
# get final fit
final_fit <- 
  fit(ext_wf, df_train)

```

```{r}
pred <- 
  predict(final_fit, new_data = df_assess) %>%
  bind_cols(df_assess)

pred %>% rmse(sales, .pred)
pred %>% rsq(sales, .pred)

```


```{r}
pred %>% 
  ggplot(aes(sales, .pred)) +
  geom_jitter(alpha = 0.5, color = "#191970") +
  geom_abline()+
  coord_obs_pred()

```


```{r}
submit <- 
  predict(final_fit, new_data = df_test) %>% 
  bind_cols(df_test) %>% 
  mutate(sales = .pred)

```


```{r}
test_pred <- 
  submit %>% select(-.pred) %>% 
  arrange(date)


```

```{r}
train_eval <- df_train %>% filter(date >= as.Date("2017-01-01"))


```

```{r}
ggplot() +
  geom_line(data = train_eval, aes(date, sales), color = "#191970") +
  geom_line(data = test_pred, aes(date, sales), color = "#8B0000") +
  scale_x_date(date_breaks = "1 month", date_labels = "%B")

```


```{r for_loop}

getPrediction <- function(i) {
  # split data
  df_train <- df_set[[i]] %>% filter(set == "train")
  df_test <- df_set[[i]] %>% filter(set == "test")
  
  df_split <- initial_split(df_train)
  df_analysis <- training(df_split)
  df_assess <- testing(df_split)
  
  # ROLLING FORECASTING ORIGIN RESAMPLING   
  df_slice <- 
    df_analysis %>% 
    rolling_origin(initial = 728, assess = 30, cumulative = TRUE,
                   skip = 30, lag = 0)
  
  
  # set the models
  xgb_spec <- 
    boost_tree(tree_depth = tune(), learn_rate = tune(), loss_reduction = tune(), 
               min_n = tune(), sample_size = tune(), trees = tune()) %>% 
    set_engine("xgboost") %>% 
    set_mode("regression")
  
  # recipe
  base_rec <- 
    recipe(sales ~ ., data = df_analysis) %>% 
    update_role(c(id, date, store_nbr, family, set, transactions, daily_sales, ratio_sales), 
                new_role = "id") %>% 
    step_impute_knn(all_predictors()) %>%
    step_zv(all_numeric_predictors())
  
  # set workflow
  base_wf <- 
    workflow() %>% 
    add_model(xgb_spec) %>% 
    add_recipe(base_rec) 
  
  
  # parameter tune and get results
  tic()
  set.seed(234)
  base_res <- 
    base_wf %>% 
    tune_grid(
      resamples = df_slice,
      grid = 5,
      metrics = metric_set(rmse),
      control = control_grid(verbose = TRUE, save_pred = FALSE, save_workflow = FALSE)
    )
  toc()
  
  print(i)
  
  # finalize workflow using best result
  final_wf <- 
    base_wf %>% 
    finalize_workflow(select_best(base_res, metric = "rmse"))
  
  
  # trained fit
  base_fit <-
    final_wf %>% 
    last_fit(df_split)
  
  ext_wf <- 
    extract_workflow(base_fit)
  
  # get final fit
  final_fit <- 
    fit(ext_wf, df_train)
  
  submit <- 
    predict(final_fit, new_data = df_test) %>% 
    bind_cols(df_test)
  
  submit <- 
    submit %>% select(id, everything()) %>% arrange(id)
  
  return(submit)
  
}

```



```{r}
submission_list = list()

for(i in 1:length(df_set)) {
  
  submission_list[[i]] <- getPrediction(i)
  
}

submission <- do.call(rbind, lapply(submission_list, function(x) as.data.frame(x[1:5])))

submission <- 
  submission %>% 
  mutate(.pred = case_when(.pred < 0 ~ 0, TRUE ~ .pred)) %>% 
  mutate(.pred = round(.pred, digits = 7)) %>% 
  arrange(id)

```



```{r}
submission <- submission %>% select(id, .pred)

names(submission) <- c("id", "sales")

write.csv(submission, file = "submission.csv", row.names = FALSE)


```


